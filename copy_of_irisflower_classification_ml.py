# -*- coding: utf-8 -*-
"""Copy of irisflower_classification_ML

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17AXv73yUqMN1VSNO130ytvqowHfIHyWB

# **Importing the libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr

import warnings
warnings.filterwarnings('ignore')

"""# **Loading the Dataset**

"""

data_frame=pd.read_csv("/content/Iris.csv")
data_frame

"""#**Data Processing**"""

data_frame.describe() #check the data statistics

data_frame.info()  #check the datatypes

data_frame.isna().sum()  #check if the dataset has null values
#if null value in particular column >15% ---> drop the column
#if null value in particular column <15% ---> use Mean, Median, Mode

data_frame.duplicated().sum()  #check if duplicated rows exists
# if there is, remove it

#Drop the ID column (since we don't need the column)
data_frame.drop(columns=['Id'], inplace=True)

data_frame.head()

#Scaling the features

#the inputs: Sepal Length, Sepal Width, Petal Length, Petal Width
features=["SepalLengthCm","SepalWidthCm","PetalLengthCm","PetalWidthCm"]

#input
x=data_frame[features].values

#output
y=data_frame['Species']

"""#**Box Plot**"""

#Plotting the data to find outliers
sns.boxplot(data=data_frame)

"""#**Join Plot**"""

sns.jointplot(x=data_frame['SepalWidthCm'],y=data_frame['PetalWidthCm'],data=data_frame,kind='hex')

sns.jointplot(x=data_frame['SepalLengthCm'],y=data_frame['PetalLengthCm'],data=data_frame,kind='hex')

"""#**Pair Plot**

"""

#find the outliers
sns.pairplot(data_frame, hue="Species", size=3, markers=["o", "s", "D"])

"""#**Feature Scaling**

"""

#seperate data into Train and Test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

"""#**Label encoder**"""

#technique in Machine Learning to convert categorical variables into numerical format
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
le.fit(y)

le.classes_

# Use mapping method to add the index to decode the output
mapping = dict(zip(le.classes_, range(len(le.classes_))))
mapping

y = le.transform(y)

"""#**Standard Scaler**"""

#To Normalization (make all atribute value in a similar range)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

# Removes the mean and scales each feature/variable to unit variance
scaler.fit(X_train)

X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""#**Model Training Libaries**"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""#**Logistic Regression**"""

# Fitting the values in Logistic Regression model
model = LogisticRegression()
model.fit(X_train_scaled, y_train)

model_prediction = model.predict(X_test_scaled)

accuracy_score(model_prediction, y_test)

"""#**K-Nearest Neighbors**

"""

# Fitting the models in K-Nearest Neighbors (KNN)

classi = KNeighborsClassifier(n_neighbors=3)
classi.fit(X_train_scaled, y_train)

classi_pred = classi.predict(X_test_scaled)

accuracy_score(y_test, classi_pred)

"""#**Support Vector Classifier (SVC)**"""

# Fitting the models in support Vector Classifier (SVC)

from sklearn.svm import SVC
svc = SVC()
svc.fit(X_train_scaled, y_train)

svc_pred = svc.predict(X_test_scaled)

accuracy_score(y_test, svc_pred)

"""#**Naive Bayes**"""

# Fitting the models in Naive Bayes

from sklearn.naive_bayes import GaussianNB
naive_b = GaussianNB()
naive_b.fit(X_train_scaled, y_train)

naive_b_pred = naive_b.predict(X_test_scaled)

accuracy_score(y_test, naive_b_pred)

"""#**Model evaluation**



"""

# Confusion Matrix: create a table that show where the predictions are wrong

confusion_matrix(y_test, model_prediction)

confusion_matrix(y_test, classi_pred)

confusion_matrix(y_test, svc_pred)

confusion_matrix(y_test, naive_b_pred)

"""#**Combinding all the model scores**"""

# All Model Scores

results = pd.DataFrame({
    'Model' : ['Logistic Regression', 'SVM', 'KNN', 'Naive Bayes'],
    'Score' : [1.0, 1.0, 0.96, 0.96]
})

results_df = results.sort_values(by="Score", ascending=False)
results_df = results_df.set_index('Score')
results_df.head(9)

"""#**Entire model prediction**"""

# Model Prediction
model_prediction

classi_pred

svc_pred

naive_b_pred

"""#**Model building and deployment**"""

#### To save the model in a pkl file

import pickle as pkl

pkl.dump(model, open('model.pkl', 'wb'))
pkl.dump(scaler, open('scaler.pkl', 'wb'))

# load the scalar.pkl
with open('scaler.pkl', 'rb') as scaler_file:
    data = pkl.load(scaler_file)

type(data)

# Normalize using standard scalar
sample_input = np.array([2.0, 5.8, 2.8, 4.2]).reshape(-1,4)
processdata = data.transform(sample_input)

processdata

# load the model.pkl
with open('model.pkl', 'rb') as model_file:
    model_data = pkl.load(model_file)

# Find ypred
model_predict = model_data.predict(processdata)

# Print the predicted class with decoded catergory label
model_predict

"""#**Interface**"""

!pip install streamlit

!npm install localtunnel

!streamlit run /streamlitapi.py &>/content/logs.txt & curl https://loca.lt/mytunnelpassword

!npx localtunnel --port 8501